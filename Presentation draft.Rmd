---
title: "Presentation draft"
author: "Victoria"
date: "20/11/2020"
output: beamer_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Comparison of Gyms and Home Workouts

```{r, echo = FALSE}

setwd("C:\\Users\\Victoria\\Documents\\MSc Data Science and Business Analytics\\MATH513\\Coursework")
```
![Image of gym.](/Users/Victoria/Documents/MSc Data Science and Business Analytics/MATH513/Coursework/gym.jpg){width=150px}  ![Image of home workout.](/Users/Victoria/Documents/MSc Data Science and Business Analytics/MATH513/Coursework/homeworkout.png){width=250px}


## Tweet Frequency 
```{r, eval = TRUE, include = FALSE, echo = FALSE, message = FALSE, warning = FALSE}
require(jsonlite)
require(rjson)
rt <- stream_in(file("rt_home_workout.json"))
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
require(ggplot2)
require(rtweet)
ts_plot(rt, "60 mins") +
  theme_minimal() + 
  theme(plot.title = element_text(face = "bold")) + 
  labs(
    x = NULL, y = NULL, 
    title = "Frequency of #homeworkout Twitter statuses",
    subtitle = "Twitter status (tweet) counts aggregated using 1-hour intervals",
    caption = "Source: Data collected from Twitter's REST API via rtweet")
```

## Tweet Frequency 
```{r, eval = TRUE, include = FALSE, echo = FALSE, message = FALSE, warning = FALSE}
require(jsonlite)
require(rjson)
rt <- stream_in(file("hash_gym_tweets_incrtweets.json"))
```

```{r, echo = FALSE, message = FALSE, warning = FALSE}
require(ggplot2)
require(rtweet)

ts_plot(rt, "60 mins") +
  theme_minimal() + 
  theme(plot.title = element_text(face = "bold")) + 
  labs(
    x = NULL, y = NULL, 
    title = "Frequency of #gym Twitter statuses",
    subtitle = "Twitter status (tweet) counts aggregated using 1-hour intervals",
    caption = "Source: Data collected from Twitter's REST API via rtweet")
```

## Most Popular Words  
```{r, echo = FALSE, message = FALSE, results='hide'}
require(jsonlite)
require(rjson)
require(dplyr)
require(tidytext)
home_workout_tweets <- stream_in(file("home_workout_tweets.json"))
home_workout_tweets$stripped_text <- gsub("http.*","",  home_workout_tweets$text)
home_workout_tweets$stripped_text <- gsub("https.*","", home_workout_tweets$stripped_text)
home_workout_tweets$stripped_text <- gsub("amp","", home_workout_tweets$stripped_text)
home_workout_tweets_clean <- home_workout_tweets %>%
  select(stripped_text) %>% 
  mutate(tweetnumber = row_number()) %>% 
  unnest_tokens(word, stripped_text)
cleaned_tweet_words <- home_workout_tweets_clean %>%
  anti_join(stop_words)
my_stop_words <- data.frame(word = c("homeworkout", "workout", "home"))
require(wordcloud)
cleaned_tweet_words_2 <- cleaned_tweet_words %>%
  anti_join(my_stop_words) 
cleaned_tweet_words_3 <- cleaned_tweet_words_2 %>%
  count(word, sort = TRUE) %>% 
  mutate(freq = n / sum(n))
head(cleaned_tweet_words_3)
with(cleaned_tweet_words_3, 
     wordcloud(word, freq, 
               min.freq = 1, 
               max.words = 50,
               random.order = FALSE, 
               colors = brewer.pal(8, "Dark2"), 
               scale = c(5.5, 0.5)))
title(main = "Wordcloud for Tweets containing #homeworkout", 
      cex.main = 2) 
```

## Sentiment Analysis 
```{r, eval = TRUE, include = FALSE, echo = FALSE, message = FALSE, warning = FALSE}
bing_word_counts <- cleaned_tweet_words_2 %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  mutate(word = reorder(word, n)) 
my_stop_words_2 <- data.frame(word = c("resistance", "isolation", "burn", "burning"))
bing_word_counts_2 <- bing_word_counts %>%
  anti_join(my_stop_words_2) 
```

```{r, echo = FALSE, message = FALSE} 
bing_word_counts_2 %>%
  group_by(sentiment) %>%
  top_n(10) %>%
  ungroup() %>%
  mutate(word = reorder(word, n)) %>%
  ggplot(aes(word, n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  coord_flip() +
  facet_wrap(~sentiment, scales = "free_y") +
  labs(title = "Most common Positive and Negative words in tweets on Home workout",
       y = "Sentiment",
       x = NULL) +
  theme(axis.text = element_text(size = 14, color = "black"), 
        axis.title = element_text(size = 14, color = "black"),
        title = element_text(size = 15))
```

## Sentiment Analysis 
```{r, eval = TRUE, include = FALSE, echo = FALSE, message = FALSE, warning = FALSE}
require(tidyr)
home_workout_sentiment <- cleaned_tweet_words_2 %>%
  inner_join(get_sentiments("bing")) %>%
  count(tweetnumber, sentiment) %>%
  spread(sentiment, n, fill = 0) %>% 
  mutate(score = positive - negative)
home_workout_sentiment %>% count(score)
sentiment_means_home_workout <- home_workout_sentiment %>% 
  summarize(mean_score = mean(score)) 
``` 

```{r, echo = FALSE, message = FALSE}
ggplot(home_workout_sentiment, 
       aes(x = score)) + 
  geom_bar(fill = "lightgreen", colour = "darkgreen") + 
  geom_vline(aes(xintercept = mean_score), data = sentiment_means_home_workout) +
  geom_text(aes(x = mean_score, 
                y = Inf, 
                label = signif(mean_score, 3)), 
            vjust = 2, 
            data = sentiment_means_home_workout) + 
  scale_x_continuous(breaks = -10:10, 
                     minor_breaks = NULL) + 
  labs(title = paste("Sentiments towards #homeworkout give a mean of", signif(sentiment_means_home_workout$mean_score, 3)),
       x = "Sentiment Score", 
       y = "Number of tweets") 
```
